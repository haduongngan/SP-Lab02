{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HMM_without A B ban.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "9K1SKLvXjZru"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Trong file này, em thực hiện y hệt cài đặt trong file HMM.ipynb. Điều khác biệt duy nhất là em chỉ sử dụng các label: [\"len\", \"xuong\", \"phai\", \"trai\", \"nhay\"] (ngoại trừ \"sil\", \"A\", \"B\" và \"ban\").\n",
        "\n",
        "Lý do cho việc làm như vậy vì em muốn thử thu nhỏ lại để thấy tình huống mà ma trận mixture covariance không bị suy biến. Ngoài ra nhóm em có ý tưởng làm bài tập cuối kì chỉ sử dụng các nhãn [\"phai\", \"trai\", \"nhay\"] nên em muốn đánh giá sơ lược khả năng mô hình có khả quan không"
      ],
      "metadata": {
        "id": "ricLdNd7n804"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Khai báo thư viện và các đường dẫn cần thiết"
      ],
      "metadata": {
        "id": "9K1SKLvXjZru"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjjHsnxdux2R",
        "outputId": "f864a131-80ba-45ad-9c04-0dd23e08e39c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting hmmlearn\n",
            "  Downloading hmmlearn-0.2.7-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (129 kB)\n",
            "\u001b[?25l\r\u001b[K     |██▌                             | 10 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |█████                           | 20 kB 20.5 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 30 kB 20.3 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 40 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 51 kB 9.7 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 61 kB 11.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 71 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 81 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 92 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 102 kB 10.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 112 kB 10.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 122 kB 10.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 129 kB 10.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.16 in /usr/local/lib/python3.7/dist-packages (from hmmlearn) (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.10 in /usr/local/lib/python3.7/dist-packages (from hmmlearn) (1.21.6)\n",
            "Requirement already satisfied: scipy>=0.19 in /usr/local/lib/python3.7/dist-packages (from hmmlearn) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.16->hmmlearn) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.16->hmmlearn) (3.1.0)\n",
            "Installing collected packages: hmmlearn\n",
            "Successfully installed hmmlearn-0.2.7\n"
          ]
        }
      ],
      "source": [
        "import librosa\n",
        "import librosa.display\n",
        "import IPython.display as ipd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "import fnmatch\n",
        "import pandas as pd\n",
        "import os.path\n",
        "import pickle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "!pip install hmmlearn\n",
        "import hmmlearn.hmm as hmm\n",
        "from sklearn.utils import shuffle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "DATA_ROOT_DIR=\"/content/drive/MyDrive/Speech/Data_14/\"\n",
        "!ls $DATA_ROOT_DIR\n",
        "DATA_MFCC_DIR=DATA_ROOT_DIR+\"MFCC/\"\n",
        "!ls $DATA_MFCC_DIR"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-EcnGnIDu8Yr",
        "outputId": "e1f9a731-5006-4a75-f368-ec19574d404f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "A  ban\tMFCC\t     model.pkl\t\tnhay  trai\n",
            "B  len\tmodel_1.pkl  model_without.pkl\tphai  xuong\n",
            "A_mfcc.npy    B_mfcc.npy    nhay_mfcc.npy  trai_mfcc.npy\n",
            "ban_mfcc.npy  len_mfcc.npy  phai_mfcc.npy  xuong_mfcc.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Xử lý dữ liệu\n",
        "Trong mục này, em chuẩn bị dữ liệu để huấn luyện và đánh giá mô hình\n",
        "\n",
        "- Load dữ liệu từ file đặc trưng MFCC đã tính toán trước đó\n",
        "- Chia tập dữ liệu train và test với tỷ lệ 70:30"
      ],
      "metadata": {
        "id": "vYWd8qYopSwa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = [\"len\", \"xuong\", \"phai\", \"trai\", \"nhay\"]\n",
        "features = []\n",
        "labels = []\n",
        "\n",
        "#Với từng label\n",
        "for cname in class_names:\n",
        "  \n",
        "  #Load file MFCC\n",
        "  mfcc_data = np.load(DATA_MFCC_DIR+cname+\"_mfcc.npy\",allow_pickle=True)\n",
        "  len_label = mfcc_data.shape[0]\n",
        "\n",
        "  #Thêm các đặc trưng vào list chung\n",
        "  for i in range(len_label):\n",
        "    labels.append(cname)\n",
        "    features.append(mfcc_data[i])\n",
        "print(len(features))\n",
        "print(len(labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GqIP8iIvvA9O",
        "outputId": "3bd8ed14-56fd-4ce0-c72c-8224817a1f08"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2481\n",
            "2481\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Thực hiện shuffle dữ liệu\n",
        "c = list(zip(features, labels))\n",
        "np.random.shuffle(c)\n",
        "features,labels = zip(*c)\n",
        "\n",
        "#Chia dữ liệu theo tỷ lệ 70:30\n",
        "X_train , X_test , y_train , y_test  = train_test_split(features , \n",
        "                                                        labels, test_size = 0.3,\n",
        "                                                        random_state=0)\n",
        "print(len(X_train))\n",
        "print(len(y_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YbeVv_O2x7Ry",
        "outputId": "64585908-bb65-4293-cbe4-953acdea8eb8"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1736\n",
            "1736\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Lấy chỉ số tương ứng với label\n",
        "gmmhmmdict = {}\n",
        "index = 0\n",
        "for cname in class_names:\n",
        "  gmmhmmdict[cname] = index\n",
        "  index = index +1\n",
        "gmmhmmdict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f397EXwvysOr",
        "outputId": "fca7c3cb-fe5b-44bb-9206-743838142fd6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'len': 0, 'nhay': 4, 'phai': 2, 'trai': 3, 'xuong': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chuẩn bị mô hình\n",
        "Trong phần này, em thực hiện:\n",
        "- Thiết lập các tham số đầu vào để huấn luyện mô hình\n",
        "- Định nghĩa mô hình nhận các tham số đó"
      ],
      "metadata": {
        "id": "A4pqjrQ1pwtJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Thiết lập các tham số cần thiết để train GMMHMM\n",
        "m_num_of_HMMStates = 3  # số trạng thái\n",
        "m_num_of_mixtures = 2  # số mixtures của mỗi hidden state\n",
        "m_level = 2 #step size\n",
        "m_covarianceType = 'diag'  # dạng ma trận covariance \n",
        "m_n_iter = 15  # số vòng lặp \n",
        "\n",
        "#khởi tạo giá trị cho startprobPrior và transmatPrior\n",
        "def initLevel(inumstates, m_level):\n",
        "    startprobPrior = np.zeros(inumstates)\n",
        "    startprobPrior[0: m_level - 1] = 1/float((m_level - 1))\n",
        "    transmatPrior = getTransmatPrior(inumstates, m_level)\n",
        "    return startprobPrior, transmatPrior\n",
        "\n",
        "#khởi tạo giá trị cho transmatPrior dựa vào step size\n",
        "def getTransmatPrior(inumstates, m_level):\n",
        "    transmatPrior = (1 / float(m_level)) * np.eye(inumstates)\n",
        "\n",
        "    for i in range(inumstates - (m_level - 1)):\n",
        "        for j in range(m_level - 1):\n",
        "            transmatPrior[i, i + j + 1] = 1. / m_level\n",
        "\n",
        "    for i in range(inumstates - m_level + 1, inumstates):\n",
        "        for j in range(inumstates - i):\n",
        "            transmatPrior[i, i + j] = 1. / (inumstates - i)\n",
        "\n",
        "    return transmatPrior\n",
        "\n",
        "startprobPrior ,transmatPrior = initLevel(m_num_of_HMMStates,m_level)"
      ],
      "metadata": {
        "id": "kAZgfNLM0Bsn"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SpeechModel:\n",
        "  def __init__(self,Class,label):\n",
        "    self.traindata = np.zeros((0,39))\n",
        "    self.Class = Class\n",
        "    self.label = label\n",
        "    self.model  = hmm.GMMHMM(n_components = m_num_of_HMMStates, n_mix = m_num_of_mixtures,\n",
        "                        transmat_prior = transmatPrior, startprob_prior = startprobPrior, \n",
        "                                    covariance_type = m_covarianceType, n_iter = m_n_iter, random_state=321)"
      ],
      "metadata": {
        "id": "6t86Znm7zxXy"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Huấn luyện mô hình\n",
        "Với mỗi label em thực hiện huấn luyện một mô hình hmm tương ứng"
      ],
      "metadata": {
        "id": "7WI3Jaz4qDoS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "speechmodels = [None] * len(class_names)\n",
        "\n",
        "for key in gmmhmmdict:\n",
        "  speechmodels[gmmhmmdict[key]] = SpeechModel(gmmhmmdict[key],key)\n",
        "\n",
        "for i in range(0,len(X_train)):\n",
        "  for j in range(0,len(speechmodels)):\n",
        "    if int(speechmodels[j].Class) == int(gmmhmmdict[y_train[i]]):\n",
        "      speechmodels[j].traindata = np.concatenate((speechmodels[j].traindata , X_train[i]))"
      ],
      "metadata": {
        "id": "xMaasNHmz6VT"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for speechmodel in speechmodels:\n",
        "    speechmodel.model.fit(speechmodel.traindata)"
      ],
      "metadata": {
        "id": "o_Tw3io200g8"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Đánh giá mô hình bằng tập test\n",
        "Trong phần này em thực hiện đánh giá mô hình sử dụng tập test đã chia bên trên. Nhãn dự đoán là nhãn ứng với mô hình mang lại score lớn nhất"
      ],
      "metadata": {
        "id": "sfGL6cam059_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = []\n",
        "\n",
        "for i in range(0,len(X_test)):\n",
        "    scores = []\n",
        "    for speechmodel in speechmodels:\n",
        "         scores.append(speechmodel.model.score(X_test[i]))\n",
        "    id  = scores.index(max(scores))\n",
        "    y_pred.append(speechmodels[id].label)\n",
        "    # print(str(np.round(scores, 3)) + \" \" + str(max(np.round(scores, 3))) +\" \"+\":\"+ speechmodels[id].label)"
      ],
      "metadata": {
        "id": "HxsVSqES01gh"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "report = classification_report(y_test, y_pred, target_names=class_names)\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qr2FwFXu1ICL",
        "outputId": "60ec7e19-78a1-443d-e84f-00b60a09cb4d"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         len       0.99      0.92      0.96       159\n",
            "       xuong       0.64      0.99      0.78       181\n",
            "        phai       0.97      0.60      0.74       128\n",
            "        trai       0.96      0.66      0.78       140\n",
            "        nhay       0.97      0.99      0.98       137\n",
            "\n",
            "    accuracy                           0.85       745\n",
            "   macro avg       0.91      0.83      0.85       745\n",
            "weighted avg       0.89      0.85      0.85       745\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "print('accuracy = ',accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQHTvhO71_SQ",
        "outputId": "fce84f03-38a4-4f11-eca0-4ea263d93d3b"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy =  0.8483221476510067\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trained_model = {}\n",
        "for key in gmmhmmdict:\n",
        "  trained_model[key] = speechmodels[gmmhmmdict[key]]\n",
        "pickle.dump(trained_model, open(DATA_ROOT_DIR+'model_without.pkl', 'wb'))"
      ],
      "metadata": {
        "id": "dK4IaJfTDcyS"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# \bDemo nhận dạng với dữ liệu mới thu"
      ],
      "metadata": {
        "id": "fQhquj1evaM3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trained_models = pickle.load(open(DATA_ROOT_DIR+'model_without.pkl', 'rb'))"
      ],
      "metadata": {
        "id": "tfI7xnm3KLq8"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_mfcc_features(file_path,n_mfcc):\n",
        "    #load file âm thanh\n",
        "    sound, sr = librosa.load(file_path)\n",
        "\n",
        "    #trích xuất đặc trưng\n",
        "    mfcc = librosa.feature.mfcc(y=sound, sr=sr, n_mfcc=n_mfcc,hop_length=512)\n",
        "    delta_mfcc = librosa.feature.delta(mfcc,width=9)\n",
        "    delta2_mfcc = librosa.feature.delta(mfcc, order=2)\n",
        "\n",
        "    #chuẩn hoá\n",
        "    mfcc_features = np.concatenate((mfcc, delta_mfcc, delta2_mfcc)).T\n",
        "    min_features = np.min(mfcc_features, axis=0)\n",
        "    max_features = np.max(mfcc_features, axis=0)\n",
        "    mfcc_features_nom = (mfcc_features - min_features) / (max_features - min_features)\n",
        "    \n",
        "    return mfcc_features_nom"
      ],
      "metadata": {
        "id": "D266fOSavp53"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_mfcc=13\n",
        "audio_file = \"/content/drive/MyDrive/Speech/Data/nhay.wav\"\n",
        "ipd.Audio(audio_file)\n",
        "# load audio files with librosa\n",
        "signal, sr = librosa.load(audio_file)\n",
        "mfccs_features = extract_mfcc_features(audio_file,n_mfcc)\n",
        "mfccs_features.shape\n",
        "# mfccs_features"
      ],
      "metadata": {
        "id": "4vlcYkd-nxfv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89704cc1-705d-4922-f719-1b8e4d4752ec"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25, 39)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores = []\n",
        "for speechmodel in trained_models:\n",
        "  scores.append(trained_models[speechmodel].model.score(mfccs_features))\n",
        "id = scores.index(max(scores))\n",
        "\n",
        "def get_key(val):\n",
        "  for key, value in gmmhmmdict.items():\n",
        "    if val == value:\n",
        "      return key\n",
        "\n",
        "print(get_key(id))"
      ],
      "metadata": {
        "id": "hitggOKRvrxI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d148ab2c-47b9-446b-f88b-ef4c24cc0f79"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nhay\n"
          ]
        }
      ]
    }
  ]
}